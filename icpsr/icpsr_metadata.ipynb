{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/{ddi:codebook:2_5}docDscr\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}titl\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}IDNo\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}producer\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}copyright\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}copyright/{ddi:codebook:2_5}ExtLink\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}titl\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}IDNo\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}IDNo\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}copyright\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}copyright/{ddi:codebook:2_5}ExtLink\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}fundAg\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}fundAg\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}grantNo\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}grantNo\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}distStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}distStmt/{ddi:codebook:2_5}distrbtr\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}distStmt/{ddi:codebook:2_5}distDate\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}biblCit\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}holdings\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}abstract\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}timePrd\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}timePrd\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}collDate\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}collDate\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}geogCover\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}anlyUnit\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}universe\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}sumDscr/{ddi:codebook:2_5}dataKind\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}dataColl\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}dataColl/{ddi:codebook:2_5}sampProc\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}dataColl/{ddi:codebook:2_5}sources\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}dataColl/{ddi:codebook:2_5}sources/{ddi:codebook:2_5}dataSrc\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}p\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}ol/{ddi:codebook:2_5}li\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}p\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes/{ddi:codebook:2_5}p\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}notes\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}method/{ddi:codebook:2_5}anlyInfo\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs/{ddi:codebook:2_5}setAvail\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs/{ddi:codebook:2_5}setAvail/{ddi:codebook:2_5}accsPlac\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs/{ddi:codebook:2_5}useStmt\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs/{ddi:codebook:2_5}useStmt/{ddi:codebook:2_5}specPerm\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs/{ddi:codebook:2_5}useStmt/{ddi:codebook:2_5}restrctn\n",
      "/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}notes\n"
     ]
    }
   ],
   "source": [
    "import lxml.etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import os \n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "parser = etree.XMLParser(recover=True)\n",
    "filepath = 'DDI/4248_ddi_2.5.xml'\n",
    "\n",
    "\n",
    "def get_tag_paths(root, path=\"\"):\n",
    "    \"\"\"Recursively extracts all tag paths from an XML tree.\"\"\"\n",
    "    paths = []\n",
    "    if path:\n",
    "        paths.append(path)\n",
    "    for child in root:\n",
    "        paths.extend(get_tag_paths(child, f\"{path}/{child.tag}\"))\n",
    "    return paths\n",
    "\n",
    "tree = ET.parse(filepath)  # Replace with your XML file\n",
    "root = tree.getroot()\n",
    "paths = get_tag_paths(root)\n",
    "for path in paths:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['DDI/100179_ddi_2.5.xml', 'DDI/100640_ddi_2.5.xml', 'DDI/101343_ddi_2.5.xml', 'DDI/106966_ddi_2.5.xml', 'DDI/20622_ddi_2.5.xml', 'DDI/36036_ddi_2.5.xml', 'DDI/36174_ddi_2.5.xml', 'DDI/37250_ddi_2.5.xml', 'DDI/38645_ddi_2.5.xml', 'DDI/38821_ddi_2.5.xml', 'DDI/39091_ddi_2.5.xml', 'DDI/4248_ddi_2.5.xml']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('DDI/')\n",
    "xml_files = []\n",
    "\n",
    "for file in files:\n",
    "    if '.xml' in file:\n",
    "        xml_files.append('DDI/' + file)\n",
    "\n",
    "print(len(xml_files))\n",
    "print(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_title = './/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}titl' # remove 'Metadata record for ' at beginning\n",
    "ds_author = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}rspStmt/{ddi:codebook:2_5}AuthEnty' # Affiliation is the attribute, no ORCiD\n",
    "ds_doi = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}titlStmt/{ddi:codebook:2_5}IDNo' # 2nd element is DOI URL\n",
    "ds_keyword = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}subject/{ddi:codebook:2_5}keyword' \n",
    "ds_abstract = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}stdyInfo/{ddi:codebook:2_5}abstract'\n",
    "ds_restriction = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}dataAccs/{ddi:codebook:2_5}useStmt/{ddi:codebook:2_5}restrctn'\n",
    "ds_access = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}notes'\n",
    "ds_date = './/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}verStmt/{ddi:codebook:2_5}version' # attribute is date\n",
    "ds_funder = './/{ddi:codebook:2_5}stdyDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}grantNo' # text is grant number, attribute is funder\n",
    "ds_license_statement = './/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}copyright'#in text\n",
    "ds_license_url = './/{ddi:codebook:2_5}docDscr/{ddi:codebook:2_5}citation/{ddi:codebook:2_5}prodStmt/{ddi:codebook:2_5}copyright/{ddi:codebook:2_5}ExtLink' # URL in attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_name(name):\n",
    "    '''Separates a name into First, Middle (if applicable) and Last, returns these elements as separate strings.'''\n",
    "    middle = \"\"\n",
    "    \n",
    "    # Check if the name contains a comma (indicating \"last, first\" or \"last, first m.\" format)\n",
    "    if ',' in name:\n",
    "        parts = name.split(\", \") # Split into a list: \"last, first\" becomes [\"last\", \"first\"]\n",
    "        last = parts[0] # Last name is everything before the comma\n",
    "        \n",
    "        # Check if there's an element after the comma\n",
    "        if len(parts) > 1:\n",
    "            first_and_middle = parts[1].split() # Split whatever was after the comma with spaces\n",
    "            first = first_and_middle[0] # First name will be the first part of that\n",
    "            \n",
    "            # Assign middle if available\n",
    "            if len(first_and_middle) > 1: # If there is a second part\n",
    "                middle = first_and_middle[1].replace(\".\", \"\") # Assign middle name as second part, remove . because DC will add it\n",
    "        else:\n",
    "            # Set first to an empty string if there's nothing after the comma\n",
    "            first = \"\"\n",
    "    else: # If the name had no comma, you can assume it is in First Last or First Middle Last format\n",
    "        parts = name.split() # Split into a list where spaces are \n",
    "        \n",
    "        first = parts[0] # First name is first element of list\n",
    "        last = parts[-1] # Last name is the last element of the list \n",
    "        \n",
    "        # Check if there is a middle name/initial \n",
    "        if len(parts) > 2: \n",
    "            middle = parts[1].replace(\".\", \"\") # Remove period if it exists\n",
    "    \n",
    "    return first, middle, last\n",
    "\n",
    "def to_html(string):\n",
    "    '''Takes in a string. If the string is not in html already (assume first character is <) wrap it in <p> ... </p>.'''\n",
    "    if string[0] != \"<\":\n",
    "        string = \"<p>\" + string + \"</p>\"\n",
    "    return(string)\n",
    "\n",
    "def list_to_string(lst):\n",
    "    '''Takes in a list of strings ['a', 'b', 'c'] and returns a single string containing the list elements, separated by commas 'a, b, c'. '''\n",
    "    if isinstance(lst, list):  # Check if the value is a list\n",
    "        return ', '.join(lst)\n",
    "    else:\n",
    "        return \"\"  # Convert non-list values to string or handle as needed\n",
    "    \n",
    "def get_lists(root, field):\n",
    "    elements = root.findall(field)\n",
    "    text = []\n",
    "    attributes = []\n",
    "    for element in elements:\n",
    "        text.append(element.text)\n",
    "        attributes.append(element.attrib)\n",
    "    return text, attributes\n",
    "\n",
    "def add_titles(xml_files):\n",
    "    titles = []\n",
    "    for file in xml_files:\n",
    "        tree = ET.parse(file, parser=parser)\n",
    "        root = tree.getroot()\n",
    "        title = get_lists(root, ds_title)[0][0]\n",
    "        titles.append(to_html(title[20:])) # Remove 'Metadata record for '\n",
    "    df = pd.DataFrame(titles, columns = ['title'])\n",
    "    return df\n",
    "\n",
    "def add_abstracts(xml_files, df):\n",
    "    abstracts = []\n",
    "    for file in xml_files:\n",
    "        tree = ET.parse(file, parser=parser)\n",
    "        root = tree.getroot()\n",
    "        abstract = get_lists(root, ds_abstract)[0][0]\n",
    "        abstracts.append(to_html(abstract))  \n",
    "    df['abstract'] = abstracts\n",
    "    return df\n",
    "\n",
    "def add_date(xml_files, df):\n",
    "    dates = []\n",
    "    for file in xml_files:\n",
    "        tree = ET.parse(file, parser=parser)\n",
    "        root = tree.getroot()\n",
    "        date = get_lists(root, ds_date)[1][0]['date']\n",
    "        dates.append(date)  \n",
    "    df['publication_date'] = dates\n",
    "    return df\n",
    "\n",
    "def add_keywords(xml_files, df):\n",
    "    keywords = []\n",
    "    for file in xml_files:\n",
    "        tree = ET.parse(file, parser=parser)\n",
    "        root = tree.getroot()\n",
    "        keyword = get_lists(root, ds_keyword)[0]\n",
    "        keywords.append(list_to_string(keyword))\n",
    "    df['keywords'] = keywords\n",
    "    return df\n",
    "\n",
    "def add_doi(xml_files, df):\n",
    "    dois = []\n",
    "    for file in xml_files:\n",
    "        tree = ET.parse(file, parser=parser)\n",
    "        root = tree.getroot()\n",
    "        doi = get_lists(root, ds_doi)[0][1]\n",
    "        dois.append(doi)\n",
    "    df['source_fulltext_url'] = dois\n",
    "    return df\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source_fulltext_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;High Intensity Interval- vs Moderate Intens...</td>\n",
       "      <td>&lt;p&gt;Purpose: To compare the effects of six week...</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>Liproproteins, Blood, Obesity, Blood Pressure,...</td>\n",
       "      <td>http://doi.org/10.3886/E53793V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;Randomization to Randomization Probability:...</td>\n",
       "      <td>&lt;p&gt;This folder contains the data, code, and da...</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>caffeine, randomization method, vigilance, moo...</td>\n",
       "      <td>http://doi.org/10.3886/E100640V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;A method for measuring human body compositi...</td>\n",
       "      <td>&lt;p&gt;The files required to replicate the results...</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>body fat, body volume, obesity , image analysis</td>\n",
       "      <td>http://doi.org/10.3886/E101343V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Illustration of measurement error models fo...</td>\n",
       "      <td>&lt;p&gt;The files\\nrequired to reproduce the result...</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>measurement error, regression calibration, mul...</td>\n",
       "      <td>http://doi.org/10.3886/E106966V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;Assessing Identity Theft Offenders' Strateg...</td>\n",
       "      <td>&lt;p&gt;The purpose of this study was to examine th...</td>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>access to information, adult offenders, federa...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR20622.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p&gt;Advanced Cognitive Training for Independent...</td>\n",
       "      <td>&lt;p&gt;The data producers have recompiled the ACTI...</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>aging population, cognitive functioning, cogni...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR36036.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;p&gt;Randomized Controlled Trial of Breakfast Re...</td>\n",
       "      <td>&lt;p&gt;This study is a multi-site, 3 parallel arm,...</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>diet, eating habits, health, health behavior, ...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR36174.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;p&gt;Post Coital DNA Recovery in Minority Proxy ...</td>\n",
       "      <td>&lt;p&gt;Introduction and Background. Minorities are...</td>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>genetics data, reproductive history, sexually ...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR37250.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;p&gt;2010 United States Census Tract Community T...</td>\n",
       "      <td>&lt;p&gt;This dataset contains two measures designed...</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>census data, census tract level, diabetes, epi...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR38645.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;p&gt;Advanced Cognitive Training for Independent...</td>\n",
       "      <td>&lt;p&gt;ACTIVE (Advanced Cognitive Training for Ind...</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>aging population, cognitive functioning, elder...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR38821.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;p&gt;Puerto Rican Elder: Health Conditions (PREH...</td>\n",
       "      <td>&lt;p&gt;This is the third wave of the PREHCO projec...</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>cognitive status, community health, demographi...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR39091.v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;p&gt;Advanced Cognitive Training for Independent...</td>\n",
       "      <td>&lt;p&gt;The data producers have recompiled the ACTI...</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>activities of daily living, aging, aging popul...</td>\n",
       "      <td>http://doi.org/10.3886/ICPSR04248.v3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   <p>High Intensity Interval- vs Moderate Intens...   \n",
       "1   <p>Randomization to Randomization Probability:...   \n",
       "2   <p>A method for measuring human body compositi...   \n",
       "3   <p>Illustration of measurement error models fo...   \n",
       "4   <p>Assessing Identity Theft Offenders' Strateg...   \n",
       "5   <p>Advanced Cognitive Training for Independent...   \n",
       "6   <p>Randomized Controlled Trial of Breakfast Re...   \n",
       "7   <p>Post Coital DNA Recovery in Minority Proxy ...   \n",
       "8   <p>2010 United States Census Tract Community T...   \n",
       "9   <p>Advanced Cognitive Training for Independent...   \n",
       "10  <p>Puerto Rican Elder: Health Conditions (PREH...   \n",
       "11  <p>Advanced Cognitive Training for Independent...   \n",
       "\n",
       "                                             abstract publication_date  \\\n",
       "0   <p>Purpose: To compare the effects of six week...       2024-11-05   \n",
       "1   <p>This folder contains the data, code, and da...       2024-11-05   \n",
       "2   <p>The files required to replicate the results...       2024-11-05   \n",
       "3   <p>The files\\nrequired to reproduce the result...       2024-11-05   \n",
       "4   <p>The purpose of this study was to examine th...       2009-03-31   \n",
       "5   <p>The data producers have recompiled the ACTI...       2015-07-29   \n",
       "6   <p>This study is a multi-site, 3 parallel arm,...       2015-08-07   \n",
       "7   <p>Introduction and Background. Minorities are...       2019-12-17   \n",
       "8   <p>This dataset contains two measures designed...       2023-03-07   \n",
       "9   <p>ACTIVE (Advanced Cognitive Training for Ind...       2023-12-11   \n",
       "10  <p>This is the third wave of the PREHCO projec...       2024-07-01   \n",
       "11  <p>The data producers have recompiled the ACTI...       2010-06-30   \n",
       "\n",
       "                                             keywords  \\\n",
       "0   Liproproteins, Blood, Obesity, Blood Pressure,...   \n",
       "1   caffeine, randomization method, vigilance, moo...   \n",
       "2     body fat, body volume, obesity , image analysis   \n",
       "3   measurement error, regression calibration, mul...   \n",
       "4   access to information, adult offenders, federa...   \n",
       "5   aging population, cognitive functioning, cogni...   \n",
       "6   diet, eating habits, health, health behavior, ...   \n",
       "7   genetics data, reproductive history, sexually ...   \n",
       "8   census data, census tract level, diabetes, epi...   \n",
       "9   aging population, cognitive functioning, elder...   \n",
       "10  cognitive status, community health, demographi...   \n",
       "11  activities of daily living, aging, aging popul...   \n",
       "\n",
       "                     source_fulltext_url  \n",
       "0        http://doi.org/10.3886/E53793V1  \n",
       "1       http://doi.org/10.3886/E100640V1  \n",
       "2       http://doi.org/10.3886/E101343V1  \n",
       "3       http://doi.org/10.3886/E106966V1  \n",
       "4   http://doi.org/10.3886/ICPSR20622.v1  \n",
       "5   http://doi.org/10.3886/ICPSR36036.v1  \n",
       "6   http://doi.org/10.3886/ICPSR36174.v1  \n",
       "7   http://doi.org/10.3886/ICPSR37250.v1  \n",
       "8   http://doi.org/10.3886/ICPSR38645.v1  \n",
       "9   http://doi.org/10.3886/ICPSR38821.v1  \n",
       "10  http://doi.org/10.3886/ICPSR39091.v1  \n",
       "11  http://doi.org/10.3886/ICPSR04248.v3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XML variables \n",
    "\n",
    "\n",
    "def build_dataframe(xml_files):\n",
    "    df = add_titles(xml_files)\n",
    "    df = add_abstracts(xml_files, df)\n",
    "    df = add_date(xml_files, df)\n",
    "    df = add_keywords(xml_files, df)\n",
    "    df = add_doi(xml_files, df)\n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "df_output = build_dataframe(xml_files)\n",
    "\n",
    "display(df_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenodo-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
